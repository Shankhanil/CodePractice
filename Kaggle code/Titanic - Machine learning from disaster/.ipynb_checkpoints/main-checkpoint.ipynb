{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Titanic Machine learning from disaster\n",
      "\n",
      "Columns     DESCRIPTION:\n",
      "survival\tSurvival\t            0 = No, 1 = Yes\n",
      "pclass      Ticket class\t        1 = 1st, 2 = 2nd, 3 = 3rd\n",
      "sex\t        Sex\t\n",
      "Age\t        Age in years\t\n",
      "sibsp\t    # of siblings / spouses aboard the Titanic\t\n",
      "parch\t    # of parents / children aboard the Titanic\t\n",
      "ticket\t    Ticket number\t\n",
      "fare\t    Passenger fare\t\n",
      "cabin\t    Cabin number\t\n",
      "embarked\tPort of Embarkation\t    C = Cherbourg, Q = Queenstown, S = Southampton\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "s = \"\"\"\n",
    "Titanic Machine learning from disaster\n",
    "\n",
    "Columns     DESCRIPTION:\n",
    "survival\tSurvival\t            0 = No, 1 = Yes\n",
    "pclass      Ticket class\t        1 = 1st, 2 = 2nd, 3 = 3rd\n",
    "sex\t        Sex\t\n",
    "Age\t        Age in years\t\n",
    "sibsp\t    # of siblings / spouses aboard the Titanic\t\n",
    "parch\t    # of parents / children aboard the Titanic\t\n",
    "ticket\t    Ticket number\t\n",
    "fare\t    Passenger fare\t\n",
    "cabin\t    Cabin number\t\n",
    "embarked\tPort of Embarkation\t    C = Cherbourg, Q = Queenstown, S = Southampton\n",
    "\n",
    "\"\"\"\n",
    "print(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "import seaborn as sns\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from  sklearn.ensemble import RandomForestClassifier\n",
    "import tensorflow as tf\n",
    "warnings.filterwarnings(action = 'ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = \"..\\Titanic - Machine learning from disaster\\\\titanic\"\n",
    "    \n",
    "FILES = os.listdir(PATH)\n",
    "\n",
    "xTrain = pd.read_csv(PATH + \"\\\\\" + \"train.csv\")\n",
    "\n",
    "xTest = pd.read_csv(PATH + \"\\\\\" + \"test.csv\")\n",
    "\n",
    "_X = xTrain.drop(columns = 'Survived', inplace = False)\n",
    "y = xTrain['Survived']\n",
    "\n",
    "X = pd.concat([_X, xTest], axis = 0)\n",
    "\n",
    "X.shape\n",
    "\n",
    "#FILES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = \"\"\"\n",
    "Useless features:\n",
    "    1. passengerID  : random numbers\n",
    "    2. Cabin number : lot's of NaN value\n",
    "    3. Ticket number\n",
    "Feature engineering :\n",
    "    1. Name : extract titles Mr. Mrs. Dr. \n",
    "    2. SipSb Parch : family size\n",
    "Others:\n",
    "    1. Pclass : categorical\n",
    "    2. Sex : categorical\n",
    "    3. Fare : continuous\n",
    "    4. Embarked : categorical \n",
    "    5. Age : continuous\n",
    "\"\"\"\n",
    "\n",
    "print(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "useless = ['PassengerId', 'Cabin', 'Ticket']\n",
    "forFeatEx = ['Name', 'SibSp', 'Parch']\n",
    "rest = ['Pclass', 'Sex', 'Fare', 'Embarked', 'Age']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove useless features\n",
    "_x = X.drop(columns = useless)\n",
    "#_xTest = xTest.drop(columns = useless)\n",
    "_x.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature extration with name\n",
    "def featEx_name(df):\n",
    "    trainL = []\n",
    "    for _strain in list(df.Name):\n",
    "        _s = _strain.split(\", \")[1]\n",
    "        trainL.append(_s.split(\" \")[0])\n",
    "    df['Salutation'] = trainL\n",
    "    return df\n",
    "def featEx_familySize(df):\n",
    "    parch = list(df.Parch)\n",
    "    sibsb = list(df.SibSp)\n",
    "    familySize = [parch[i] + sibsb[i] for i in range(len(parch))]\n",
    "    df['FamSize'] = familySize\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "__x = featEx_name(_x)\n",
    "#__xTest = featEx_name(_xTest)\n",
    "__x.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "__x = featEx_familySize(__x)\n",
    "#__xTest = featEx_familySize(__xTest)\n",
    "__x.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createDumm(df, cols):\n",
    "    for c in cols:\n",
    "        d = pd.get_dummies(df[c])\n",
    "        df = pd.concat([df, d], axis = 1)\n",
    "    return df\n",
    "\n",
    "categorical = ['Pclass', 'Sex', 'Embarked', 'Salutation']\n",
    "__x= createDumm(__x, cols = categorical)\n",
    "#__xTest= createDumm(__xTest, cols = categorical)\n",
    "__x = __x.drop(columns = categorical, inplace = False)\n",
    "#__xTest = __xTest.drop(columns = categorical, inplace = False)\n",
    "\n",
    "__x.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "__x = __x.drop(columns = ['Name'])\n",
    "#__xTest = __xTest.drop(columns = ['Name'])\n",
    "#__xTest.head()\n",
    "__x.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lots of NaN values in TRAIN::age, TEST::age, and 1 NaN value in TEST::fare\n",
    "#__x.fillna(__x.mean(), inplace = True)\n",
    "\n",
    "#\n",
    "\n",
    "def imput(X, mode = 'mean'):\n",
    "    if mode == 'mean':\n",
    "        _X = X.fillna(X.mean(), inplace = False)\n",
    "    elif mode == 'reg':\n",
    "        return 0\n",
    "    return _X\n",
    "\n",
    "#__x = imput(__x, mode = 'mean')\n",
    "__x.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#visualizing heat map. \n",
    "__x.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def useLR(X, y):\n",
    "    _lenofy = y.shape[0]\n",
    "    xtrain = X[0:_lenofy]\n",
    "    xtest = X[_lenofy:]\n",
    "    \n",
    "    lr = LogisticRegression()\n",
    "    \n",
    "    lr.fit(xtrain, y)\n",
    "    \n",
    "    return lr.predict(xtest)\n",
    "def useXGBoost(X, y):\n",
    "    return 0\n",
    "def Linreg ( __x):\n",
    "\n",
    "   \n",
    "    imputtest = __x[ __x['Age'].isna() ].drop(columns = 'Age', inplace = False)\n",
    "    imputtrain = __x[ __x['Age'] >= 0]\n",
    "    imputtrainx = imputtrain.drop(columns = 'Age', inplace = False)\n",
    "    imputtrainy = imputtrain['Age']\n",
    "    imputtrainx.fillna(0, inplace = True)\n",
    "    imputtrainx.fillna(0, inplace = True)\n",
    "    imputtest.fillna(0, inplace = True)\n",
    "    #print(imputtrainx.isna().any(), imputtest.isna().any())\n",
    "\n",
    "    linr = LinearRegression()\n",
    "    \n",
    "    linr.fit(imputtrainx, imputtrainy)\n",
    "    \n",
    "    return list(linr.predict(imputtest)), imputtest\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = \"\"\"\n",
    "\n",
    "#_train[0:10]\n",
    "#train.head\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "impAge, imputtest= Linreg(__x)\n",
    "for i in range(len(impAge)):\n",
    "    if impAge[i] < 0:\n",
    "        impAge[i] = 0\n",
    "imputtest['Age'] = list(impAge)\n",
    "imputtest.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in imputtest.index:\n",
    "    __x.at[i, 'Age'] = imputtest.loc[i].Age\n",
    "    \n",
    "__x.fillna(0, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = useLR(__x, y)\n",
    "res\n",
    "data = {'PassengerId' : list(range(892, 1310)), 'Survived' : res }\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "df.to_csv(\"result.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Sequential([\n",
    "    keras.layers.Flatten(input_shape=(28, 28)),\n",
    "    keras.layers.Dense(128, activation='relu'),\n",
    "    keras.layers.Dense(10)\n",
    "])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
